{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import urllib2\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_content(title):\n",
    "    def build_query_url(page):\n",
    "        # Build query\n",
    "        queryUrl = \"http://en.wikipedia.org/w/api.php/?action=query\"\n",
    "        title = \"titles=%s\" % page \n",
    "        content = \"prop=extracts&exlimit=max&explaintext\"\n",
    "        rvprop= \"rvprop=timestamp|content\"\n",
    "        dataformat = \"format=json\"\n",
    "        query = \"%s&%s&%s&%s&%s\" % (queryUrl, title, content, rvprop, dataformat)\n",
    "        return query\n",
    "\n",
    "    def fetch_page(url):\n",
    "        response = urllib2.urlopen(url)\n",
    "        json_reponse = json.load(response)\n",
    "        pages = json_reponse['query']['pages']\n",
    "        pages_key = pages.keys()[0]\n",
    "        extract = pages[pages_key]['extract'].encode('utf-8')\n",
    "        return extract\n",
    "    \n",
    "    url = build_query_url(title)\n",
    "    content = fetch_page(url)\n",
    "    return content\n",
    "\n",
    "def save_to_file(content, page_name):\n",
    "        filename = 'congress115/%s.txt' % page_name\n",
    "        f = open(filename, \"a\")\n",
    "        f.write(content)\n",
    "        f.close()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe, which contains page names for 115th congress\n",
    "url_base = 'https://raw.githubusercontent.com/suneman/socialgraphs2018/master/files/data_US_congress/'\n",
    "df = pd.read_csv(url_base + 'H115.csv')\n",
    "page_names = df.WikiPageName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch each wikipage and save to a txt file\n",
    "for page_name in page_names:\n",
    "        content = fetch_content(page_name)\n",
    "        save_to_file(content, page_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
